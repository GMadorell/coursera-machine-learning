
# Neural Networks: Representation

## Non-Linear Hypotheses

Used for classification.

Logistic regression is hard to apply when we have a lot of features that are not linearly separable. That is because we must apply a high order polynomial function combining those, which will have a looot of features.

Computer vision: detecting cars.
Training set = cars and not cars.
If we take the pixels directly as features, we can have a lot of features (500x500 img = 2500 features), and we need an algorithm that can take that.
Can't use high order polynomial here, as we would have too many features.

Conclussion: we can use neural networks for that.

## Neurons and the Brain
NN are motivated by the brain, as their name tells.
Turns out that our brain "learns" using a "single algorithm", based on the connection of the neurons.

(The video shows examples of how the human brain is incredible - such as a boy that is able to make sounds so he doesn't hit things, much like a sonar).

## Model Representation I
Neuron = unit that gets inputs by the dendrites, does some calculation and then outputs some value to the axon.

![neuron](http://i.imgur.com/2GG1aj1.png)

The output (axon) is fed as the input of another neuron, along with the axons of other neurons as well.

### Neuron representation
Note that there's a bias unit that has weight equal to 1, much like the column of ones we added on the anterior models.

![neruon representation](http://i.imgur.com/Cy8RPA5.png)

### Neural network representation
It's just an aggrupation of single neurons, separated in layers.
Hidden layer = all of them which are not input nor output layers.

![neural network representation](http://i.imgur.com/5VoSQZC.png)

Some notation in neural networks:

![nn notation](http://i.imgur.com/bu75S3a.png)

## Model representation II
We'll see a vectorized implementation of neural networks.

### Forward propagation
It's the process of feeding forward the activations of the neurons so we can calculate the output.

Basic formulas of a basic neural network

![basic network](http://i.imgur.com/vtp0mqp.png)

We can see that each step resembles the multiplication of $\theta$ and $x$, so we can easily vectorize it.

Notation: $z_1^{(2)}$ will be the value inside  $a_1^{(2)}$ so that $a_1^{(2)} = g(z_1^{(2)})$.

Then, we vectorize it such as:

![forward propagation vectorization](http://i.imgur.com/9JIqKFx.png)

### Learning its own features
If we take each layer separately, we have a simple logistic regression model.
The only difference is that, for layers that are not the input one, the features are the activation values instead of the original features.
That means that the network is "learning" it's own features which are finally fed into the final logistic regression model.


## Examples and Intuitions I
Shows an AND function solved by a neural network.
Shows an OR function solved by a neural network.

## Examples and Intuitions II
Shows the NOT function.
Shows the XOR example and why a single layer (linear function) cannot solve it.

Shows a pretty interesting video of Lecun's early research on handwritten digit classification.

## Multiclass Classification
Extension of one vs all method.
We basically have one output unit per classification class.

![multiclass network](http://i.imgur.com/7HJjqwz.png)



## Very Basic TLDR
$\theta$ values are the weights (values situated at the arrows between units).
$\theta^{(i)}$ = all weights from layer i to layer i + 1.
$\theta_12^{(i)}$ = single weight from layer i to layer i + 1, from the neuron 2 of layer i to the neuron 1 to the layer i + 1.
Dimensions: if layer i has 2 units and layer i+1 has 4 units -> dimensions = (4, 3)

------------

$a$ values are the activation of the units.
$a_1^{(2)}$ = activation of neuron 1 from layer 2.







































