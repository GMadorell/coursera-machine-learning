


## Classification ##
Applications:

 * Email: spam/no
 * Online transactions: fraudulents or no.
 * Tumor: malignant / benign.

In this examples, the target is binary (1 or 0).  
We'll start with two classes and then move on to multiclass problems.

We could implement the binary classification with linear regression between 1 and 0 thresholding at 0.5. What happens is that in some problems it doesn't quite work well, though, in those in which fitting a line / equation doesn't quite work well.  
Therefore, using lineal regression isn't a good idea for classification problems.

Our goal is a model that works well with this kind of problems.  
Even though the name is Logistical Regression, it's a classification algorithm. Yeah, the name is badly assigned :S.

## Hypothesis representation  ##
We want our classifier to output always a number between 0 and 1.  

    0 <= hθ(x) <= 1

We will implement the hyphotesis using the logistic function (also named sigmoid function) g(z):

    hθ(x) = g(θ' * x)
    g(z) = 1 / (1 + e^-z)

The hyphotesis will thus become an estimated probability that y = 1 on input x.

    hθ(x) = p(y = 1 | x ; θ)


## Decision Boundary ##
We can threshold the result of hθ(x) (for example at 0.5) to predict whether the result should be 1 or 0.  
(This is almost all graphs description - look slides).

### Non-Linear Decision Boundaries ###
Use parametrized features (x1^2, x2^2, x1^3 ...), similarly to linear regression.  


## Cost Function ##
We can't really use the same cost function (J) that we were using with the linear regression, because it's non-convex.  
We are going to use the following one instead:

    Cost(hθ(x), y) = |     -log(hθ(x)) if y = 1
                     | -log(1 - hθ(x)) if y = 0
This function penalizes errors by a very large cost, and costs 0 if the prdiction is exact, which is exactly what we want.  

Together, this two functions that form the cost function form a fully convex function. (Similar to a rollercoaster fall and then rise, one function is the falling part and the other one is the rising part).


## Simplified Cost Function and Gradient Descent ##
### Simplifying the Cost Function ###
Take advantage that y is either 0 or 1 to compress the cost function.  

    Cost(hθ(x), y) = -y * log(hθ(x)) - (1-y) * log(1 - hθ(x))
Basically, a part of this equation always gets multiplied by zero, and thus gets "eliminated".  
Therefore, we can write the full cost function as:  

    J(θ) = -1/m * [sum from i to m: Cost(hθ(x[i]), y[i])]

### Gradient Descent ###
We want to minimize J over θ.  
We can use the standard gradient descent template from last week:

    repeat until convergence:
        θj := θj - alpha * [derivate over θj: J(θ)]
            where alpha is the learning rate.

And, after derivating:

    repeat until convergence:
        θj := θj - alpha * [sum from i to m: (hθ(x[i]) - y[i]) * x[i][j]]
            where alpha is the learning rate.

It's exactly what we had for linear regression!!  
The only difference is that now we use a different hθ(x).  

## Advanced Optimization ##
Algorithms more sophisticathed than gradient descent:

 * Conjugate gradient
 * BFGS
 * L-BFGS

This algs don't need to manually pick alpha (they do it in a inner loop). They are also much faster than gradient descent.  

Use them as fminunc in Octave.


## Multiclass Classification: One-vs-All ##
Algorithm that classifies not only to two classes, but to > 2.  

The idea behind one-vs-all is simply taking the problem and transform it into different binary classification subproblems.  
After that, apply normal logistic regression.  

Example: We have 3 classes: 1, 2, 3.  
One model tries to classify 1 vs others. Another one tries 2 vs others. The last one tries 3 vs others. To do that, change labels of the training set to binary.  

When predicting: Get the probability of every different model. Pick the class that gives a higher classification probability.  


## TLDR ##

### Hypothesis ###
    hθ(x) = g(θ' * x)
    g(z) = 1 / (1 + e^-z)

### Gradient Descent ###
    repeat until convergence:
        θj := θj - alpha * [sum from i to m: (hθ(x[i]) - y[i]) * x[i][j]]
            where alpha is the learning rate.






