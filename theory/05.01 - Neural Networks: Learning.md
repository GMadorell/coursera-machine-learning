# Neural Networks: Learning

[TOC]

## Cost function
$L$ = Number of layers.
$s_l$ = number of units in layer $l$ (excluding the bias unit).

Different problems:

* Binary classification: 1 output unit.
* Multi-class classification: K classes, K output units.

The cost function in neural networks will be a generalization of what we had before in logistic regression.

Cost function will now output a vector: $h_\theta(x) \in R^K$ where $(h_\theta(x))_i = i^{th}$ output.

$$
J(\theta) = - \frac{1}{m} [ \sum_{i=1}^{m} \sum_{k=1}^{K} y_k^{(i)} \log(h_\theta(x^{(i)}))_k + (1- y_k^{(i)}) \log(1 - h_\theta(x^{(i)}))_k] + \frac{\lambda}{2m} \sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_l + 1} (\theta_{ji}^{(l)})^2
$$

It's basically the same but applying it to every output unit at the same time, and then ignoring the bias units in the regularization part (that's why it starts from 1 and not from 0).

## Backpropagation algorithm
In order to minimize $J(\theta)$ we need to be able to compute:

* $J(\theta)$
* $\frac{\delta}{\delta\theta_{ij}^{(l)}}J(\theta)$

How to calculate the partial derivatives?

First we need to use the forward propagation to predict the values.

Next, we need to calculate the intuition value $\delta_j^{(l)}$, which is the error of node $j$ in layer $l$.

For each output unit (Layer L = 4, for example):
$\delta_j^{(4)} = a_j^{(4)} - y_j$
Which can then be vectorized to:
$\delta^{(4)} = a^{(4)} - y$

After that, we calculate the intuitions for the other layers (we go from the last one to the first one, that's why it's called backpropagation):
$d^{(3)} = (\theta^{(3)})^T \delta^{(4)} .* g'(z^{(3)})$
$d^{(2)} = (\theta^{(2)})^T \delta^{(3)}
 .* g'(z^{(2)})$
(There's no $\delta^{(1)}$)

----

But, what if we have more than one training sample?
Set $\Delta_{ij}^{(l)} = 0$ for all $l$, $i$, $j$). This will be used as acumulators to compute the partial derivatives.

For $i$ = 1 to $m$:
Set $a^{(1)} = x^{(i)}$
Perform forward propagation to compute $a^{(l)}$ for $l = 2, 3, ..., L$
Using $y^{(i)}$, compute $\delta^{(L)} = a^{(L)} -  y^{(i)}$
Compute $\delta^{(L - 1)}, \delta^{(L - 2)},...,\delta^{(2)}$
$\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + a_j^{(l)}\delta_i^{(l+1)}$, vectorized to: $\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)} (a^{(l)})^T$
ENDFOR
$D_{ij}^{(l)} := \frac{1}{m}\Delta_{ij}^{(l)} + \lambda\Theta_{ij}^{(l)}$ if $j \neq 0$
$D_{ij}^{(l)} := \frac{1}{m}\Delta_{ij}^{(l)}$ if $j = 0$

The D terms are the partial derivatives (proof is left as an exercice for the reader).

## Backpropagation intuition
Explains the forward propagation algorithm in depth. Also explains how the BP (backward propagation) is similar to FP but in reverse order, from the end to the beggining of the net.

## Implementation Note - Unrolling Parameters
Optimized optimization algorithms such as fminunc expect vectors instead of matrices. We must vectorize our matrices in order to be able to use those algorithms correctly..

Example:
Imagine we have a nn with 3 layers and $s_1 = 10, s_2 = 10, s_3 = 1$
We will then have $\Theta^{(1)} \in R^{10x11}, \Theta^{(2)} \in R^{10x11}$ and $ \Theta^{(3)} \in R^{1x11}$.
We will also have $D^{(1)} \in R^{10x11}, D^{(2)} \in R^{10x11}$ and $D{(3)} \in R^{1x11}$.

In order to unroll that we can simply do:
thetaVec = [ theta1(:); theta2(:), theta3 ]
DVec = [ D1(:); D2(:); D3(:) ]

In order to roll the data back we can do:
theta1 = reshape(thetaVec(1:100), 10, 11)
...

### Learning algorithm
1. Have initial parameters $\Theta^{(1)}, \Theta^{(2)}$ and $ \Theta^{(3)}$.
2. Unroll to get initialTheta to pass to fminunc.
3. Also need to construct the cost function. In this function we need to roll the theta values again and then use forward and back propagation to get the D values. Afterwards, we need to unroll D matrices into a vector.


## Gradient Checking
Back prop is notorious for having small bugs and still appear to work correctly.

We use gradient checking in order to detect this problems.

We can approximate derivatives such as:
$$
\frac{\delta}{\delta\theta} J(\theta) = \frac{J(\theta+\epsilon) - J(\theta-\epsilon)}{2\epsilon}
$$
With $\epsilon$ being a very small number.

Basically, what we do is getting two points near the one we want to calculate and create a line between those. We use that line as the slope of the derivative.

If $\Theta$ is a parameter vector, then:
$$
\frac{\delta}{\delta\theta_1} J(\theta) = \frac{J(\theta_1+\epsilon,\theta_2,...,\theta_n) - J(\theta_1-\epsilon, \theta_2, ..., \theta_n)}{2\epsilon}
$$
And so on for the others. We simply use the $\epsilon$ for the derivative we are calculating at that exact instant.
This can be easily implemented using a for loop and the unrolled version of $\theta$.

### Implementation Note
* Implement backprop to compute DVec.
* Implement numerical gradient (the one we just discussed above) check to compute gradApprox.
* Make sure they give very similar values.
* Turn off gradient checking once you're sure your implementation works as expected. Numerical gradient is very slow.

## Random Initialization
Gradient descend/advanced optimization methods need an initial value for $\Theta$.
We can't set the values to zeros. If we do that, all the neurons will be computing the same "features", as their weights will be the same.
Backpropagation derivative values will end up being the same ones as well, so it's very bad to initialize everything to the same number.

In order to solve this problem (called Symmetry Breaking) we simply initialize very $\Theta$ value to a random number bein [$-\epsilon,\epsilon$].


## Putting It Together
### Architecture
When training a nn, we first need a network architecture.
Number of input units: Dimension of features $x^{(i)}$.
Number of output units: Number of classes.
Number of hidden layers: 1 hidden layer or if >1 hidden layer, have same number of hidden units in every layer. This is only a default, it's obviously very hard to know this.

### Training
1. Randomly initialize weights.
2. Implement FP to get $h_\Theta(x^{(i)})$ for any $x^{(i)}$
3. Implement code to compute cost function $J(\Theta)$.
4. Implement BP to compute partial derivatives $\frac{\delta}{\delta\Theta_{jk}^{(l)}}J(\Theta)$
5. Use gradient checking to compare partial derivatives computed using BP vs numerical estimate. Don't do this in production!
6. Use gradient descend or advanced optimization method with BP to try to minimize $J(\Theta)$ as a function of the parameters $\Theta$.
















