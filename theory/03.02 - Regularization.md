

## The Problem of Overfitting ##
Underfitting = Bad performance on the training set. High Bias.  

Overfitting = Bad performance on the test set, even though we might get a good score on the training set. That means that the algorithm has high variance (failed to generalize).  
It comes when we have too many features, so we fit the data perfectly, the model tries too hard to fit the dataset.  

Sometimes we can't simply reduce features, which is quite manual and time intensive. We could use something like PCA, though. If we drop features we can lose information, some details about our data.  

We can use regularization instead: keep all features but penalize the θ values.


## Cost Function ##
The idea is that, if we have small values for the θ values:

 * We will have simpler hypothesis.
 * Less prone to overfitting.

What we're going to do is modify our cost function to penalize the features.  
We add the following:
    
    + lambda * [sum 1 to n: θ[j]^2]

So our cost function will look similar to:

    J(θ)= 1/(2m) * ∑(hθ(x(i))−y(i))^2 + λ*∑θ[j]^2

λ too large -> underfitting.


## Regularized Linear Regression ##
We don't penalize θ0, so we tract it differently.  
Gradient descend: 

    repeat until convergence:
        θ0 := θ0 - alpha * 1/m * [sum x over training_samples(or m)] ((h(x) - y)^2 * x[0][i])

        θj := θj(1 - alpha * λ/m) - alpha * 1/m * [sum x over training_samples(or m)] ((h(x) - y)^2 * x)

Basically, what we just added shrinks the value of the thethas that are not the zeroth one. 

Normal equation:  

    θ = pinv(X'*X + λ*Id)*X'*y            
The Id above corresponds to the identity matrix of (n + 1) where n is the amount of features. BUT, the topleft number of this matrix IS SET TO ZERO.


## Regularized Logistic Regression ##
Logistic regression can also overfit if we have too many features (or high polynomial features).  
Remember cost function:

    Cost(hθ(x), y) = -y * log(hθ(x)) - (1-y) * log(1 - hθ(x))
    J(θ) = -1/m * [sum from i to m: Cost(hθ(x[i]), y[i])]

We now add the penalization part:
    
    J(θ) = -1/m * [sum from i to m: Cost(hθ(x[i]), y[i])] + λ*∑θ[j]^2**

Remember that we dont penalize the first thetha (the zeroth one).

The gradient descent is the same one as the linear regression one (remember that the hypothesis is the part that changes).




